{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import regularizers\nimport tensorflow.keras.utils as ku \nimport numpy as np\nimport re\nimport tensorflow as tf","metadata":{"id":"jdhdgnyBzxt1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer()\ndata = open('../input/nlp-task/NLP task.txt').read()\ncorpus = data.lower().split(\".\")\nfor i in range(0,len(corpus)):\n  s = re.sub(' +',' ',(re.sub(r'[^\\w]', ' ', corpus[i])))\n  corpus[i] = s\nprint(len(corpus))\ntokenizer.fit_on_texts(corpus)\ntotal_words = len(tokenizer.word_index) + 1","metadata":{"id":"_Ahf5Qakz-GU","outputId":"7bf6b957-e92e-49bc-f9f4-98325b049098","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_sequences = []\nfor j in corpus:\n token_list = tokenizer.texts_to_sequences([j])[0]\n for i in range(1, len(token_list)):\n  n_gram_sequence = token_list[:i+1]\n  input_sequences.append(n_gram_sequence)","metadata":{"id":"Vi8NT8W-0p9w","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pad sequences \nmax_sequence_len = max([len(x) for x in input_sequences])\ninput_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))","metadata":{"id":"JW-ibCBj5JYS","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create predictors and label\npredictors, label = input_sequences[:,:-1],input_sequences[:,-1]\nlabel = ku.to_categorical(label, num_classes=total_words)","metadata":{"id":"xLdrl6Fu5Pwn","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\nmodel.add(Bidirectional(LSTM(150, return_sequences = True)))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(100))\nmodel.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\nmodel.add(Dense(total_words, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(model.summary())","metadata":{"id":"5NBPXWIEzv1R","outputId":"cd676dd1-5416-4713-ffd9-bdcf956e553d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\n\nfilepath = \"model_training.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='loss',\n                             verbose=1, save_best_only=True,\n                             mode='min')\ncallbacks = [checkpoint]","metadata":{"id":"0ukDhugA9L8J","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(predictors, label, epochs=500, verbose=1,callbacks=callbacks)","metadata":{"id":"RiDIPvwi6hg0","outputId":"72a74ebf-5ba6-43a1-9f58-be5da8547427","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"model1.h5\")","metadata":{"id":"swsV26fWJrE0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nmodel = keras.models.load_model('./model_training.hdf5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_text = \"sherlock was always\"\nnext_words = 5\n  \nfor _ in range(next_words):\n token_list = tokenizer.texts_to_sequences([seed_text])[0]\n token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n predicted = model.predict_classes(token_list, verbose=0)\n output_word = \"\"\n for word, index in tokenizer.word_index.items():\n  if index == predicted:\n   output_word = word\n   break\n seed_text += \" \" + output_word\nprint(seed_text)","metadata":{"id":"kdQggwItJ3fa","trusted":true},"execution_count":null,"outputs":[]}]}